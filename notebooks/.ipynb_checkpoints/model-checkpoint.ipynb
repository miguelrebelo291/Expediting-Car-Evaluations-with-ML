{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b83dc1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd44cf10-8eb7-4a26-859f-fc8c8a8c4af2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4910858-4154-40dc-8ad8-4af7412f1cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing original data and previously worked dataframe \n",
    "train = pd.read_csv(\"../project_data/original_data/train.csv\")\n",
    "df_train = pd.read_csv(\"../project_data/handout_data/training_handout.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5aa17f-abbf-406c-a103-3af358f999e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582593b1-2bda-4ce1-85fa-d8b008cf1a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f4fceb-66f5-4bb3-8c9f-349fada4ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnamed 0 column\n",
    "df_train = df_train.drop(columns=['Unnamed: 0'])\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d473f3-3e87-4582-bb86-fe9bfbeb8078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop mileage per year cause i dont feel its goudd\n",
    "df_train = df_train.drop(columns=[\"mileage_per_year\"])\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4c0f10",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d858813",
   "metadata": {},
   "outputs": [],
   "source": [
    "miss = df_train.isna().sum()\n",
    "mv = pd.DataFrame({\"missing\": miss[miss>0], \"missing_%\": (miss[miss>0]/len(df_train)*100).round(2)}).sort_values(\"missing_%\", ascending=False)\n",
    "if not mv.empty:\n",
    "    print(\"\\nMissing-values summary (non-zero):\")\n",
    "    print(mv.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab5a4bc-10c0-4019-88ad-2f207042003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these lines are worth dog shait and are 0.06 % of data\n",
    "df_train[df_train[\"brand\"].isnull()]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751711a4-4fc9-4656-8ce7-4197dcff80cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train[\"brand\"].notnull()]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6238dafc-7f41-4025-88c2-9de0b646466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train[\"model\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3293dd",
   "metadata": {},
   "source": [
    "**Plan**: Median imputation for numeric, most_frequent for categoricals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26fc285-d84c-47cf-b828-53a618b70890",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6511c482",
   "metadata": {},
   "source": [
    "### Data Scaling | Dealing with Categorical Features | Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a905d7-3240-4e53-b20d-c674af3decbb",
   "metadata": {},
   "source": [
    "### GUILERMI TRANSFORMERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dcea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RareLabelGrouper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, min_prop=0.005, column=None):\n",
    "        self.min_prop = min_prop\n",
    "        self.column = column\n",
    "        self.keep_values_ = None\n",
    "    def fit(self, X, y=None):\n",
    "        s = X if isinstance(X, pd.Series) else pd.Series(X.iloc[:,0] if hasattr(X, \"iloc\") else X[:,0])\n",
    "        vc = s.value_counts(dropna=False)\n",
    "        total = len(s)\n",
    "        keep = vc[vc / total >= self.min_prop].index\n",
    "        self.keep_values_ = set(keep.tolist())\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        s = X if isinstance(X, pd.Series) else pd.Series(X.iloc[:,0] if hasattr(X, \"iloc\") else X[:,0])\n",
    "        return pd.DataFrame(np.where(s.isin(self.keep_values_), s, \"Other\"),\n",
    "                            columns=[self.column if self.column else \"col\"])\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column): self.column = column\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X): return pd.DataFrame(X[self.column])\n",
    "\n",
    "class CustomWinsorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables, lower_bound=0.01, upper_bound=0.99):\n",
    "        self.variables = variables\n",
    "        self.lower_bound = lower_bound\n",
    "        self.upper_bound = upper_bound\n",
    "        self.limits_ = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for var in self.variables:\n",
    "            if var in X.columns:\n",
    "                lower_limit = X[var].quantile(self.lower_bound)\n",
    "                upper_limit = X[var].quantile(self.upper_bound)\n",
    "                self.limits_[var] = (lower_limit, upper_limit)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        for var, (lower_limit, upper_limit) in self.limits_.items():\n",
    "            if var in X.columns:\n",
    "                X_transformed[var] = np.clip(X_transformed[var], lower_limit, upper_limit)\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc19c24f-227e-4c19-895f-ff269550fb7b",
   "metadata": {},
   "source": [
    "### MODEL 0 MIKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03543228-e7db-4828-8a58-632ba0a96ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>price</th>\n",
       "      <th>transmission</th>\n",
       "      <th>mileage</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>tax</th>\n",
       "      <th>mpg</th>\n",
       "      <th>engineSize</th>\n",
       "      <th>car_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [brand, model, price, transmission, mileage, fuelType, tax, mpg, engineSize, car_age]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing reformed cars\n",
    "df_train = df_train[~(df_train[\"car_age\"] > 45)]\n",
    "df_train[df_train[\"car_age\"] > 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f91edb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [c for c in df_train.columns if c != \"price\"]\n",
    "\n",
    "X = df_train[feature_cols].copy()\n",
    "y = df_train[\"price\"].copy()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=44, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28cb7e1",
   "metadata": {},
   "source": [
    "Log the target variable since it´s a variable whit a great tail (a lot of outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e71d5a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_transformed = np.log1p(y_train)\n",
    "y_val_transformed = np.log1p(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17db64c4",
   "metadata": {},
   "source": [
    "Scaling\n",
    "\n",
    "- **Why scale:** Linear/regularized models are scale-sensitive. Numeric features can have very different ranges (ex: mileage vs engine size), which biases coefficients.\n",
    "\n",
    "- **Choice:** **StandardScaler** for numeric columns (after imputation and outlier capping).\n",
    "\n",
    "- **StandardScaler over MinMaxScaler:** Standardization centers and normalizes variance—well-aligned with Ridge/Lasso penalties and keeps One-Hot Enconding interpretable. All scaling is fit on the training fold only within the pipeline to ensure that there are **no leakage**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85290478",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b744f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = [c for c in X_train.columns if c not in numeric_cols]\n",
    "without_model = [c for c in X_train.columns if c not in numeric_cols + ['model']]\n",
    "skewness = X_train[numeric_cols].skew(numeric_only=True).sort_values(ascending=False)\n",
    "log_candidates = [c for c, s in skewness.items() if np.isfinite(s) and s > 1.0]\n",
    "log_candidates = [c for c in log_candidates if (X_train[c].dropna() >= 0).all()]\n",
    "outlier_variable = ['tax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa5222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log1p_selective(df_num):\n",
    "    df_num = pd.DataFrame(df_num, columns=numeric_cols)\n",
    "    for c in log_candidates:\n",
    "        df_num[c] = np.log1p(df_num[c])\n",
    "    return df_num\n",
    "\n",
    "log_transformer = FunctionTransformer(log1p_selective, validate=False)\n",
    "\n",
    "numeric_pipeline = Pipeline([('winsor', CustomWinsorizer(variables=outlier_variable, lower_bound=0.01, upper_bound=0.99)), (\"imputer\", SimpleImputer(strategy=\"median\")),(\"log1p_skewed\", log_transformer), (\"scaler\", scaler)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbf96be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = []\n",
    "cats.append((\"cat\",\n",
    "                 Pipeline([(\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                           (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\", sparse_output=False))]),\n",
    "                without_model))\n",
    "cats.append((\"model_collap\",\n",
    "                 Pipeline([(\"select\", ColumnSelector(\"model\")),\n",
    "                           (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                           (\"rare\", RareLabelGrouper(min_prop=0.005, column=\"model\")),\n",
    "                           (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\", sparse_output=False))]),\n",
    "                 [\"model\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6d7cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([(\"num\", numeric_pipeline, numeric_cols), *cats], remainder=\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deefe237",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = Pipeline([(\"prep\", preprocessor)]).fit(X_train, y_train)\n",
    "n_total = tmp.transform(X_train.iloc[:5]).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17cbbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad82849",
   "metadata": {},
   "source": [
    "## 5. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb914f9b",
   "metadata": {},
   "source": [
    "Following initial data preprocessing steps, which included the **removal of several irrelevant columns**, we employed **Recursive Feature Elimination (RFE)** to determine the optimal feature subset for our linear regression model. \n",
    "\n",
    "A **holdout** validation approach was utilized to evaluate model performance with varying numbers of features, using the **Mean Absolute Error (MAE)** as the primary evaluation metric. \n",
    "- This process identified an optimal subset consisting of 66 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fca209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.arange(1,n_total+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501dc94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "best_model = None\n",
    "high_score=None\n",
    "n_feat=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc018aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_sel in grid:\n",
    "    model = LinearRegression()\n",
    "    pipe = Pipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"rfe\", RFE(estimator=model, n_features_to_select=n_sel)),\n",
    "        (\"linreg\", LinearRegression()),\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train_transformed)\n",
    "    pred_log = pipe.predict(X_val)\n",
    "    pred_original_scale = np.expm1(pred_log)\n",
    "    mae = mean_absolute_error(y_val, pred_original_scale)\n",
    "    records.append({\"n_selected\": n_sel, \"MAE\": mae})\n",
    "    score = mae\n",
    "    if (high_score is None) or (score < high_score):\n",
    "        high_score = score\n",
    "        best_model = pipe\n",
    "df_best = pd.DataFrame(records).sort_values([\"MAE\"]).reset_index(drop=True)\n",
    "print(\"Optimum number of features: %d\" % df_best.iloc[0]['n_selected'])\n",
    "print(\"Score with %d features: %f\" % (df_best.iloc[0]['n_selected'], df_best.iloc[0]['MAE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e6d6c6",
   "metadata": {},
   "source": [
    "## 6. Model and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664551e0",
   "metadata": {},
   "source": [
    "The project focuses on a regression problem with the objective of predicting used car prices. The following ML algorithms were selected for evaluation: \n",
    "- **Linear Regression:** Used as a baseline model due to its simplicity and interpretability.\n",
    "- **Lasso Regression:** Explored for its ability to perform automatic feature selection by driving some coefficients to zero.\n",
    "- **Decision Tree Regressor:** Implemented to capture potential non-linear relationships and more complex interactions between features, ultimately yielding the best performance.\n",
    "\n",
    "**Assessment Strategy:** A consistent holdout split with a fixed random_state was maintained throughout the work to ensure reproducibility and avoid data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7398c6a",
   "metadata": {},
   "source": [
    "We start by implementing the optimal model (for linear regression) identified in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615ed0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_log = best_model.predict(X_val) \n",
    "pred_original_scale = np.expm1(pred_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52161934",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d4aa16",
   "metadata": {},
   "source": [
    "- Primary metric: **MAE**, because it is in price units, offering direct interpretability, and is less sensitive to outliers compared with other metrics (ex:MSE).\n",
    "\n",
    "- Secondary: **RMSE** (penalizes large errors) and **R²** (variance explained, for context)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c342d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_val, pred_original_scale)\n",
    "rmse = mean_squared_error(y_val, pred_original_scale, squared=False)\n",
    "r2 = r2_score(y_val, pred_original_scale)\n",
    "print(\"\\n--- Model Performance (Best RFE) ---\")\n",
    "print(f\"Main Metric (MAE): {high_score:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f46e14",
   "metadata": {},
   "source": [
    "#### Other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f084fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_test = {\n",
    "    \"Lasso\": LassoCV(cv=5, random_state=44),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(random_state=44)\n",
    "}\n",
    "\n",
    "high_score_2 = None\n",
    "best_model_2 = None\n",
    "best_model_2_name = \"\"\n",
    "records = []\n",
    "\n",
    "for name, model in models_to_test.items():\n",
    "    pipe = Pipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"model\", model),\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train_transformed)\n",
    "    pred_log = pipe.predict(X_val)    \n",
    "    pred_original_scale = np.expm1(pred_log)\n",
    "\n",
    "    #metrics\n",
    "    mae = mean_absolute_error(y_val, pred_original_scale)\n",
    "    rmse = mean_squared_error(y_val, pred_original_scale, squared=False)\n",
    "    r2 = r2_score(y_val, pred_original_scale)\n",
    "\n",
    "    records.append({\"Model\": name, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2})\n",
    "\n",
    "    if (high_score_2 is None) or (mae < high_score_2):\n",
    "        high_score_2 = mae\n",
    "        best_model_2 = pipe\n",
    "        best_model_2_name = name\n",
    "\n",
    "print(\"Results for all models:\")\n",
    "results_df = pd.DataFrame(records).sort_values(by=\"MAE\").reset_index(drop=True)\n",
    "print(results_df)\n",
    "\n",
    "print(f\"Best model: {best_model_2_name}\")\n",
    "print(f\"MAE metric for the best model: {high_score_2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fc8f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_log = best_model_2.predict(X_val) \n",
    "pred_original_scale = np.expm1(pred_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c9fed4",
   "metadata": {},
   "source": [
    "#### Plot some visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9439f58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=y_val, y=pred_original_scale, alpha=0.6)\n",
    "lims = [min(y_val.min(), pred_original_scale.min()), max(y_val.max(), pred_original_scale.max())]\n",
    "plt.plot(lims, lims, color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "plt.title('Actual vs Predicted Car price')\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fa25c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_val - pred_original_scale\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=pred_original_scale, y=residuals, alpha=0.6)\n",
    "\n",
    "plt.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "plt.title('Residuals vs Predicted Car Prices')\n",
    "plt.xlabel('Predicted Price')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803edd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(residuals, kde=True, bins=50)\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.xlabel('Residual Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fe415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the best model for use in test.csv dataset\n",
    "#joblib.dump(best_model_2, 'best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4075c05b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
